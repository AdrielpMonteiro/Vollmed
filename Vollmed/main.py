
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd 
from sklearn.naive_bayes import MultinomialNB 
from sklearn.pipeline import Pipeline 
import numpy as np 
import google.generativeai as genai 
import json 


genai.configure(api_key="AIzaSyCT1eEjgr6hzZPIdKxvi6MDeWWEuhoVP_c")

def chat_google_ai(mensagem):
    try:
        model = genai.GenerativeModel("gemini-2.0-flash-lite")  
        response = model.generate_content(mensagem)
        return response.text
    except Exception as e:
        return f"Erro: {e}"
    

#while True: 
    #texto = input("Voc√™->  ")
    #if texto.lower() == "sair":
   ##     break
   ##     resposta = chat_google_ai(texto)
        print(f"Gemini: {resposta}")
        print("-" * 40)

##print(chat_google_ai("Ol√°, bom dia!"))


Frases =  [
    ##Sauda√ß√µes
    "Boa Dia   ",
    "Boa tarde ",
    "Boa noite  ",
    "Oi ",
    "Tudo bem? ",


    ##Ajuda
    "Preciso de ajuda",
    "Preciso de auxilio",
    "Gostaria ",
    
    ##informa√ß√µes
    "Qual hor√°rio de funcionamento",
    "Que horas voc√™s abrem", 
    "Telefone da clinica",

    ##cancelamento  
    "Quero cancelar meu plano",
    "cancelamento",
    "n√£o quero mais continuar com plano ",

    ##Exaemes
    "Exame",
    "quero saber valores dos meus exames",
    "Resultado Exaemes",
    "Exames",

]


categorias = [
    "SAUDA√á√ÉO","SAUDA√á√ÉO","SAUDA√á√ÉO","SAUDA√á√ÉO","SAUDA√á√ÉO",
    "AJUDA","AJUDA","AJUDA",
    "INFORMA√á√ïES","INFORMA√á√ïES","INFORMA√á√ïES",
    "CANCELAMENTO","CANCELAMENTO","CANCELAMENTO",
    "EXAMES","EXAMES","EXAMES","EXAMES"
]


modelo = Pipeline([
    ('vetorizacao', CountVectorizer()),
    ('classificador', MultinomialNB())
])


respostas = {
    "SAUDACA√á√ÉO: Ol√° Bem vindo , a Clinica VollMed ! "

    "AJUDA: Ol√° Bem vindo ,  Como posso ajud√°-l√≥ hoje? "

    "INFORMA√á√ïES: üìã **Informa√ß√µes da Cl√≠nica:**\n‚Ä¢ Hor√°rio: Segunda a Sexta, 7h √†s 19h\n‚Ä¢ Telefone: (11) 3333-4444\n‚Ä¢ Endere√ßo: Rua Medical, 123 - Centro\n‚Ä¢ WhatsApp: (11) 98888-7777"

    "CANCELAMENTO: Poxa que pena , vou te transferir para um representante ! Espero que muda de opni√£o e continue conosco! "

    "EXAMES: Ol√° \n Exames Disponiv√©is  \n*  Agendamento de Exames \n "

}



modelo.fit(Frases, categorias) 

def chat_google_ai(mensagem):
    try:
        model = genai.GenerativeModel("gemini-2.0-flash-lite")  
        response = model.generate_content(mensagem)
        return response.text
    except Exception as e:
        return f"Erro: {e}"


# Nessa Fun√ß√£o, o chatbot responde com respostas fixas
def verificar_mensagem(mensagem: str) -> str:
    categoria = modelo.predict([mensagem.lower()])[0]

    if categoria in respostas: 
        return respostas[categoria]
    else: 
        return chat_google_ai(mensagem)
    
usuario = input ("digite seu nome: ")

def salvar_hist(usuario,mensagem,resposta): 
    historico = carregar_hist(usuario)
    historico.append({"mensagem": mensagem , "resposta" : resposta })
    with open(f'{usuario}_historico.json','w') as file:
        json.dump(historico,file,indent=4)

def carregar_hist(usuario):
    try:
        with open(f'{usuario}_historico.json','r') as file:
            return json.load(file)
    except FileNotFoundError:
        return []

historico = carregar_hist(usuario)


#Teste de Confian√ßa:
def confian√ßa (mensagem: str, liminar: float = 0.4):

    #Prever a probabilidade
    probabilidades = modelo.predict_proba([mensagem.lower()])[0]

    #Encontra a categoria que tem a maior probabilidade
    indice_max = probabilidades.argmax()
    probabilidade_max = probabilidades[indice_max]
    categoria_prevista = modelo.classes_[indice_max]

    #Maio ou menor?
    if probabilidade_max >= liminar and categoria_prevista in respostas:
        return respostas[categoria_prevista] #Aqui retorna a resposta fixa se a confian√ßa for maior que a liminar
    
    else:
        return chat_google_ai(mensagem) #Aqui consulta o Gemini se a confian√ßa for menor que a liminar


while True: 
    texto = input(f"{usuario} -- ").lower().strip()
    if texto.lower() == "sair":
        print("chat encerrado")
        break

    #Vai ser a reposta fixa ou a do Gemini?
    if texto in respostas:
        resposta = respostas [texto]
    else:
        resposta = confian√ßa (texto)
        
    print(f"Gemini: {resposta}")
    print("-" * 40)
    salvar_hist(usuario, texto, resposta)






##print(chat_google_ai("Ol√°, bom dia!"))

#entrada = input("Digite uma frase para o chatbot: ")
saida = modelo.predict([texto])[0]
##print(f"Categoria prevista: {saida[0]}")

